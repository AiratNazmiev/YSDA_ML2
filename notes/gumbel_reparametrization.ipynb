{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "num_states = 10  # number of dice's sides\n",
    "# values: [1, 2, ..., num_states]\n",
    "\n",
    "theta = torch.randn(num_states, requires_grad=True, device=device)\n",
    "optimizer = torch.optim.SGD([theta], lr=1e-3, momentum=0.99)\n",
    "\n",
    "temperature = 1.0\n",
    "temperature_gamma = 1.0#0.98\n",
    "temperature_min = 0.1\n",
    "\n",
    "gumbel_gen = distr.Gumbel(0, 1)\n",
    "batch_size = 2**14\n",
    "\n",
    "num_steps = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loss:\n",
    "    def __init__(self, loss_func, str_descr):\n",
    "        self.loss_func = loss_func\n",
    "        self.str_descr = str_descr\n",
    "        \n",
    "    def __call__(self, x, y=None):\n",
    "        return self.loss_func(x) if y is None else self.loss_func(x, y)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.str_descr\n",
    "\n",
    "def entropy_loss(probs):\n",
    "    entropy = -(probs * torch.log(probs)).sum(-1)\n",
    "    return -(entropy.mean())\n",
    "\n",
    "def max_mean_loss(probs):\n",
    "    x = torch.arange(1, probs.shape[-1] + 1).to(probs.device)\n",
    "    E_x = (x * probs).sum(-1)\n",
    "    return -E_x.mean()\n",
    "\n",
    "def max_var_loss(probs):\n",
    "    x = torch.arange(1, probs.shape[-1] + 1, device=probs.device, dtype=probs.dtype)\n",
    "\n",
    "    E_x = (x * probs).sum(-1)\n",
    "    E_x2 = (x**2 * probs).sum(-1)\n",
    "\n",
    "    variance = E_x2 - E_x**2\n",
    "\n",
    "    return -variance.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_func = Loss(max_mean_loss, \"Mean\")\n",
    "#loss_func = Loss(entropy_loss, \"Entropy (in nats)\")\n",
    "loss_func = Loss(max_var_loss, \"Variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Variance: 9.097\n",
      "Probabilities: [0.09  0.085 0.01  0.221 0.08  0.066 0.054 0.018 0.244 0.131]\n",
      "Step 1000, Variance: 20.250\n",
      "Probabilities: [0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.5]\n",
      "Step 2000, Variance: 20.250\n",
      "Probabilities: [0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.5]\n",
      "Step 3000, Variance: 20.250\n",
      "Probabilities: [0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.5]\n",
      "Step 4000, Variance: 20.250\n",
      "Probabilities: [0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.5]\n",
      "Step 5000, Variance: 20.250\n",
      "Probabilities: [0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.5]\n",
      "Step 6000, Variance: 20.250\n",
      "Probabilities: [0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.5]\n",
      "Step 7000, Variance: 20.250\n",
      "Probabilities: [0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.5]\n",
      "Step 8000, Variance: 20.250\n",
      "Probabilities: [0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.5]\n",
      "Step 9000, Variance: 20.250\n",
      "Probabilities: [0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.5]\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "for step in range(num_steps):\n",
    "    gumbel_noise = gumbel_gen.sample((batch_size, num_states)).to(device)\n",
    "    gumbel_noise= torch.zeros_like(gumbel_noise)\n",
    "    \n",
    "    softmax_probs = F.softmax((theta + gumbel_noise) / temperature, dim=-1)\n",
    "    \n",
    "    loss = loss_func(softmax_probs)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        temperature = max(temperature * temperature_gamma, temperature_min)\n",
    "    \n",
    "    if step % 1000 == 0:\n",
    "        true_probs = F.softmax(theta, dim=-1)\n",
    "        print(f\"Step {step}, {str(loss_func)}: {-loss.item():.3f}\")\n",
    "        print(f\"Probabilities: {true_probs.detach().cpu().numpy().round(3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
